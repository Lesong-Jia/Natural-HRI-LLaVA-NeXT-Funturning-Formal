{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.2684989429175475,
  "eval_steps": 500,
  "global_step": 600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.021141649048625793,
      "grad_norm": 3.2641284465789795,
      "learning_rate": 9.943622269203665e-05,
      "loss": 1.8329,
      "step": 10
    },
    {
      "epoch": 0.042283298097251586,
      "grad_norm": 3.0306153297424316,
      "learning_rate": 9.873150105708245e-05,
      "loss": 0.8838,
      "step": 20
    },
    {
      "epoch": 0.06342494714587738,
      "grad_norm": 2.6407196521759033,
      "learning_rate": 9.802677942212827e-05,
      "loss": 0.6398,
      "step": 30
    },
    {
      "epoch": 0.08456659619450317,
      "grad_norm": 2.7250168323516846,
      "learning_rate": 9.732205778717407e-05,
      "loss": 0.5225,
      "step": 40
    },
    {
      "epoch": 0.10570824524312897,
      "grad_norm": 2.4781999588012695,
      "learning_rate": 9.661733615221987e-05,
      "loss": 0.4996,
      "step": 50
    },
    {
      "epoch": 0.12684989429175475,
      "grad_norm": 1.5468742847442627,
      "learning_rate": 9.591261451726569e-05,
      "loss": 0.4929,
      "step": 60
    },
    {
      "epoch": 0.14799154334038056,
      "grad_norm": 1.9576400518417358,
      "learning_rate": 9.520789288231149e-05,
      "loss": 0.4615,
      "step": 70
    },
    {
      "epoch": 0.16913319238900634,
      "grad_norm": 1.1997599601745605,
      "learning_rate": 9.45031712473573e-05,
      "loss": 0.3667,
      "step": 80
    },
    {
      "epoch": 0.19027484143763213,
      "grad_norm": 1.8085527420043945,
      "learning_rate": 9.379844961240311e-05,
      "loss": 0.3779,
      "step": 90
    },
    {
      "epoch": 0.21141649048625794,
      "grad_norm": 1.7876033782958984,
      "learning_rate": 9.309372797744891e-05,
      "loss": 0.3997,
      "step": 100
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 1.6855469942092896,
      "learning_rate": 9.238900634249473e-05,
      "loss": 0.3445,
      "step": 110
    },
    {
      "epoch": 0.2536997885835095,
      "grad_norm": 3.2093067169189453,
      "learning_rate": 9.168428470754053e-05,
      "loss": 0.3677,
      "step": 120
    },
    {
      "epoch": 0.2748414376321353,
      "grad_norm": 1.77158522605896,
      "learning_rate": 9.097956307258634e-05,
      "loss": 0.3274,
      "step": 130
    },
    {
      "epoch": 0.2959830866807611,
      "grad_norm": 2.5883092880249023,
      "learning_rate": 9.027484143763215e-05,
      "loss": 0.3208,
      "step": 140
    },
    {
      "epoch": 0.3171247357293869,
      "grad_norm": 2.9249589443206787,
      "learning_rate": 8.957011980267795e-05,
      "loss": 0.3559,
      "step": 150
    },
    {
      "epoch": 0.3382663847780127,
      "grad_norm": 1.415008783340454,
      "learning_rate": 8.886539816772375e-05,
      "loss": 0.3333,
      "step": 160
    },
    {
      "epoch": 0.3594080338266385,
      "grad_norm": 1.7056607007980347,
      "learning_rate": 8.816067653276955e-05,
      "loss": 0.3975,
      "step": 170
    },
    {
      "epoch": 0.38054968287526425,
      "grad_norm": 2.413480520248413,
      "learning_rate": 8.745595489781536e-05,
      "loss": 0.295,
      "step": 180
    },
    {
      "epoch": 0.40169133192389006,
      "grad_norm": 2.3529722690582275,
      "learning_rate": 8.675123326286117e-05,
      "loss": 0.3149,
      "step": 190
    },
    {
      "epoch": 0.42283298097251587,
      "grad_norm": 2.0868256092071533,
      "learning_rate": 8.604651162790697e-05,
      "loss": 0.2934,
      "step": 200
    },
    {
      "epoch": 0.4439746300211416,
      "grad_norm": 3.9069836139678955,
      "learning_rate": 8.534178999295279e-05,
      "loss": 0.3125,
      "step": 210
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 1.4566326141357422,
      "learning_rate": 8.463706835799859e-05,
      "loss": 0.3382,
      "step": 220
    },
    {
      "epoch": 0.48625792811839325,
      "grad_norm": 1.5116759538650513,
      "learning_rate": 8.39323467230444e-05,
      "loss": 0.2853,
      "step": 230
    },
    {
      "epoch": 0.507399577167019,
      "grad_norm": 0.9641360640525818,
      "learning_rate": 8.322762508809021e-05,
      "loss": 0.3031,
      "step": 240
    },
    {
      "epoch": 0.5285412262156448,
      "grad_norm": 1.2844618558883667,
      "learning_rate": 8.252290345313601e-05,
      "loss": 0.3049,
      "step": 250
    },
    {
      "epoch": 0.5496828752642706,
      "grad_norm": 2.0487964153289795,
      "learning_rate": 8.181818181818183e-05,
      "loss": 0.3541,
      "step": 260
    },
    {
      "epoch": 0.5708245243128964,
      "grad_norm": 2.393864154815674,
      "learning_rate": 8.111346018322763e-05,
      "loss": 0.3125,
      "step": 270
    },
    {
      "epoch": 0.5919661733615222,
      "grad_norm": 3.5810577869415283,
      "learning_rate": 8.040873854827343e-05,
      "loss": 0.2548,
      "step": 280
    },
    {
      "epoch": 0.6131078224101479,
      "grad_norm": 1.5710983276367188,
      "learning_rate": 7.970401691331925e-05,
      "loss": 0.2331,
      "step": 290
    },
    {
      "epoch": 0.6342494714587738,
      "grad_norm": 5.464710712432861,
      "learning_rate": 7.899929527836505e-05,
      "loss": 0.2742,
      "step": 300
    },
    {
      "epoch": 0.6553911205073996,
      "grad_norm": 1.554824709892273,
      "learning_rate": 7.829457364341086e-05,
      "loss": 0.2836,
      "step": 310
    },
    {
      "epoch": 0.6765327695560254,
      "grad_norm": 1.3638132810592651,
      "learning_rate": 7.758985200845667e-05,
      "loss": 0.2716,
      "step": 320
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 0.9735655784606934,
      "learning_rate": 7.688513037350247e-05,
      "loss": 0.2985,
      "step": 330
    },
    {
      "epoch": 0.718816067653277,
      "grad_norm": 1.8684269189834595,
      "learning_rate": 7.618040873854828e-05,
      "loss": 0.2143,
      "step": 340
    },
    {
      "epoch": 0.7399577167019028,
      "grad_norm": 0.8613377213478088,
      "learning_rate": 7.547568710359408e-05,
      "loss": 0.2983,
      "step": 350
    },
    {
      "epoch": 0.7610993657505285,
      "grad_norm": 1.6502243280410767,
      "learning_rate": 7.477096546863988e-05,
      "loss": 0.2574,
      "step": 360
    },
    {
      "epoch": 0.7822410147991543,
      "grad_norm": 2.3814468383789062,
      "learning_rate": 7.40662438336857e-05,
      "loss": 0.2745,
      "step": 370
    },
    {
      "epoch": 0.8033826638477801,
      "grad_norm": 1.7846670150756836,
      "learning_rate": 7.33615221987315e-05,
      "loss": 0.2889,
      "step": 380
    },
    {
      "epoch": 0.8245243128964059,
      "grad_norm": 0.9130303263664246,
      "learning_rate": 7.265680056377732e-05,
      "loss": 0.2198,
      "step": 390
    },
    {
      "epoch": 0.8456659619450317,
      "grad_norm": 3.2325668334960938,
      "learning_rate": 7.195207892882312e-05,
      "loss": 0.2396,
      "step": 400
    },
    {
      "epoch": 0.8668076109936576,
      "grad_norm": 3.4203267097473145,
      "learning_rate": 7.124735729386892e-05,
      "loss": 0.2517,
      "step": 410
    },
    {
      "epoch": 0.8879492600422833,
      "grad_norm": 1.1659820079803467,
      "learning_rate": 7.054263565891474e-05,
      "loss": 0.2636,
      "step": 420
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.8766434192657471,
      "learning_rate": 6.983791402396054e-05,
      "loss": 0.2939,
      "step": 430
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 1.3382691144943237,
      "learning_rate": 6.913319238900634e-05,
      "loss": 0.222,
      "step": 440
    },
    {
      "epoch": 0.9513742071881607,
      "grad_norm": 1.438628077507019,
      "learning_rate": 6.842847075405216e-05,
      "loss": 0.2687,
      "step": 450
    },
    {
      "epoch": 0.9725158562367865,
      "grad_norm": 0.7959738373756409,
      "learning_rate": 6.772374911909796e-05,
      "loss": 0.2557,
      "step": 460
    },
    {
      "epoch": 0.9936575052854123,
      "grad_norm": 1.8739782571792603,
      "learning_rate": 6.701902748414378e-05,
      "loss": 0.2779,
      "step": 470
    },
    {
      "epoch": 1.014799154334038,
      "grad_norm": 1.2330316305160522,
      "learning_rate": 6.631430584918958e-05,
      "loss": 0.2635,
      "step": 480
    },
    {
      "epoch": 1.0359408033826638,
      "grad_norm": 2.0109777450561523,
      "learning_rate": 6.560958421423538e-05,
      "loss": 0.2069,
      "step": 490
    },
    {
      "epoch": 1.0570824524312896,
      "grad_norm": 2.0927159786224365,
      "learning_rate": 6.490486257928118e-05,
      "loss": 0.2105,
      "step": 500
    },
    {
      "epoch": 1.0782241014799154,
      "grad_norm": 1.885388731956482,
      "learning_rate": 6.420014094432699e-05,
      "loss": 0.2696,
      "step": 510
    },
    {
      "epoch": 1.0993657505285412,
      "grad_norm": 0.7001839876174927,
      "learning_rate": 6.34954193093728e-05,
      "loss": 0.217,
      "step": 520
    },
    {
      "epoch": 1.120507399577167,
      "grad_norm": 0.8424420952796936,
      "learning_rate": 6.27906976744186e-05,
      "loss": 0.2135,
      "step": 530
    },
    {
      "epoch": 1.1416490486257929,
      "grad_norm": 1.6278246641159058,
      "learning_rate": 6.20859760394644e-05,
      "loss": 0.2155,
      "step": 540
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 1.3050992488861084,
      "learning_rate": 6.138125440451022e-05,
      "loss": 0.2124,
      "step": 550
    },
    {
      "epoch": 1.1839323467230445,
      "grad_norm": 1.8095475435256958,
      "learning_rate": 6.0676532769556024e-05,
      "loss": 0.2641,
      "step": 560
    },
    {
      "epoch": 1.20507399577167,
      "grad_norm": 1.178304672241211,
      "learning_rate": 5.997181113460183e-05,
      "loss": 0.2189,
      "step": 570
    },
    {
      "epoch": 1.226215644820296,
      "grad_norm": 2.0943214893341064,
      "learning_rate": 5.926708949964764e-05,
      "loss": 0.1863,
      "step": 580
    },
    {
      "epoch": 1.2473572938689217,
      "grad_norm": 2.0824389457702637,
      "learning_rate": 5.8562367864693445e-05,
      "loss": 0.2438,
      "step": 590
    },
    {
      "epoch": 1.2684989429175475,
      "grad_norm": 1.4540592432022095,
      "learning_rate": 5.785764622973926e-05,
      "loss": 0.2246,
      "step": 600
    }
  ],
  "logging_steps": 10,
  "max_steps": 1419,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 5.0452886003084544e+17,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
