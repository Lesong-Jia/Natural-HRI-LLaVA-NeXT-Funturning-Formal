{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 2.9598308668076108,
  "eval_steps": 500,
  "global_step": 1400,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.021141649048625793,
      "grad_norm": 3.2641284465789795,
      "learning_rate": 9.943622269203665e-05,
      "loss": 1.8329,
      "step": 10
    },
    {
      "epoch": 0.042283298097251586,
      "grad_norm": 3.0306153297424316,
      "learning_rate": 9.873150105708245e-05,
      "loss": 0.8838,
      "step": 20
    },
    {
      "epoch": 0.06342494714587738,
      "grad_norm": 2.6407196521759033,
      "learning_rate": 9.802677942212827e-05,
      "loss": 0.6398,
      "step": 30
    },
    {
      "epoch": 0.08456659619450317,
      "grad_norm": 2.7250168323516846,
      "learning_rate": 9.732205778717407e-05,
      "loss": 0.5225,
      "step": 40
    },
    {
      "epoch": 0.10570824524312897,
      "grad_norm": 2.4781999588012695,
      "learning_rate": 9.661733615221987e-05,
      "loss": 0.4996,
      "step": 50
    },
    {
      "epoch": 0.12684989429175475,
      "grad_norm": 1.5468742847442627,
      "learning_rate": 9.591261451726569e-05,
      "loss": 0.4929,
      "step": 60
    },
    {
      "epoch": 0.14799154334038056,
      "grad_norm": 1.9576400518417358,
      "learning_rate": 9.520789288231149e-05,
      "loss": 0.4615,
      "step": 70
    },
    {
      "epoch": 0.16913319238900634,
      "grad_norm": 1.1997599601745605,
      "learning_rate": 9.45031712473573e-05,
      "loss": 0.3667,
      "step": 80
    },
    {
      "epoch": 0.19027484143763213,
      "grad_norm": 1.8085527420043945,
      "learning_rate": 9.379844961240311e-05,
      "loss": 0.3779,
      "step": 90
    },
    {
      "epoch": 0.21141649048625794,
      "grad_norm": 1.7876033782958984,
      "learning_rate": 9.309372797744891e-05,
      "loss": 0.3997,
      "step": 100
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 1.6855469942092896,
      "learning_rate": 9.238900634249473e-05,
      "loss": 0.3445,
      "step": 110
    },
    {
      "epoch": 0.2536997885835095,
      "grad_norm": 3.2093067169189453,
      "learning_rate": 9.168428470754053e-05,
      "loss": 0.3677,
      "step": 120
    },
    {
      "epoch": 0.2748414376321353,
      "grad_norm": 1.77158522605896,
      "learning_rate": 9.097956307258634e-05,
      "loss": 0.3274,
      "step": 130
    },
    {
      "epoch": 0.2959830866807611,
      "grad_norm": 2.5883092880249023,
      "learning_rate": 9.027484143763215e-05,
      "loss": 0.3208,
      "step": 140
    },
    {
      "epoch": 0.3171247357293869,
      "grad_norm": 2.9249589443206787,
      "learning_rate": 8.957011980267795e-05,
      "loss": 0.3559,
      "step": 150
    },
    {
      "epoch": 0.3382663847780127,
      "grad_norm": 1.415008783340454,
      "learning_rate": 8.886539816772375e-05,
      "loss": 0.3333,
      "step": 160
    },
    {
      "epoch": 0.3594080338266385,
      "grad_norm": 1.7056607007980347,
      "learning_rate": 8.816067653276955e-05,
      "loss": 0.3975,
      "step": 170
    },
    {
      "epoch": 0.38054968287526425,
      "grad_norm": 2.413480520248413,
      "learning_rate": 8.745595489781536e-05,
      "loss": 0.295,
      "step": 180
    },
    {
      "epoch": 0.40169133192389006,
      "grad_norm": 2.3529722690582275,
      "learning_rate": 8.675123326286117e-05,
      "loss": 0.3149,
      "step": 190
    },
    {
      "epoch": 0.42283298097251587,
      "grad_norm": 2.0868256092071533,
      "learning_rate": 8.604651162790697e-05,
      "loss": 0.2934,
      "step": 200
    },
    {
      "epoch": 0.4439746300211416,
      "grad_norm": 3.9069836139678955,
      "learning_rate": 8.534178999295279e-05,
      "loss": 0.3125,
      "step": 210
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 1.4566326141357422,
      "learning_rate": 8.463706835799859e-05,
      "loss": 0.3382,
      "step": 220
    },
    {
      "epoch": 0.48625792811839325,
      "grad_norm": 1.5116759538650513,
      "learning_rate": 8.39323467230444e-05,
      "loss": 0.2853,
      "step": 230
    },
    {
      "epoch": 0.507399577167019,
      "grad_norm": 0.9641360640525818,
      "learning_rate": 8.322762508809021e-05,
      "loss": 0.3031,
      "step": 240
    },
    {
      "epoch": 0.5285412262156448,
      "grad_norm": 1.2844618558883667,
      "learning_rate": 8.252290345313601e-05,
      "loss": 0.3049,
      "step": 250
    },
    {
      "epoch": 0.5496828752642706,
      "grad_norm": 2.0487964153289795,
      "learning_rate": 8.181818181818183e-05,
      "loss": 0.3541,
      "step": 260
    },
    {
      "epoch": 0.5708245243128964,
      "grad_norm": 2.393864154815674,
      "learning_rate": 8.111346018322763e-05,
      "loss": 0.3125,
      "step": 270
    },
    {
      "epoch": 0.5919661733615222,
      "grad_norm": 3.5810577869415283,
      "learning_rate": 8.040873854827343e-05,
      "loss": 0.2548,
      "step": 280
    },
    {
      "epoch": 0.6131078224101479,
      "grad_norm": 1.5710983276367188,
      "learning_rate": 7.970401691331925e-05,
      "loss": 0.2331,
      "step": 290
    },
    {
      "epoch": 0.6342494714587738,
      "grad_norm": 5.464710712432861,
      "learning_rate": 7.899929527836505e-05,
      "loss": 0.2742,
      "step": 300
    },
    {
      "epoch": 0.6553911205073996,
      "grad_norm": 1.554824709892273,
      "learning_rate": 7.829457364341086e-05,
      "loss": 0.2836,
      "step": 310
    },
    {
      "epoch": 0.6765327695560254,
      "grad_norm": 1.3638132810592651,
      "learning_rate": 7.758985200845667e-05,
      "loss": 0.2716,
      "step": 320
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 0.9735655784606934,
      "learning_rate": 7.688513037350247e-05,
      "loss": 0.2985,
      "step": 330
    },
    {
      "epoch": 0.718816067653277,
      "grad_norm": 1.8684269189834595,
      "learning_rate": 7.618040873854828e-05,
      "loss": 0.2143,
      "step": 340
    },
    {
      "epoch": 0.7399577167019028,
      "grad_norm": 0.8613377213478088,
      "learning_rate": 7.547568710359408e-05,
      "loss": 0.2983,
      "step": 350
    },
    {
      "epoch": 0.7610993657505285,
      "grad_norm": 1.6502243280410767,
      "learning_rate": 7.477096546863988e-05,
      "loss": 0.2574,
      "step": 360
    },
    {
      "epoch": 0.7822410147991543,
      "grad_norm": 2.3814468383789062,
      "learning_rate": 7.40662438336857e-05,
      "loss": 0.2745,
      "step": 370
    },
    {
      "epoch": 0.8033826638477801,
      "grad_norm": 1.7846670150756836,
      "learning_rate": 7.33615221987315e-05,
      "loss": 0.2889,
      "step": 380
    },
    {
      "epoch": 0.8245243128964059,
      "grad_norm": 0.9130303263664246,
      "learning_rate": 7.265680056377732e-05,
      "loss": 0.2198,
      "step": 390
    },
    {
      "epoch": 0.8456659619450317,
      "grad_norm": 3.2325668334960938,
      "learning_rate": 7.195207892882312e-05,
      "loss": 0.2396,
      "step": 400
    },
    {
      "epoch": 0.8668076109936576,
      "grad_norm": 3.4203267097473145,
      "learning_rate": 7.124735729386892e-05,
      "loss": 0.2517,
      "step": 410
    },
    {
      "epoch": 0.8879492600422833,
      "grad_norm": 1.1659820079803467,
      "learning_rate": 7.054263565891474e-05,
      "loss": 0.2636,
      "step": 420
    },
    {
      "epoch": 0.9090909090909091,
      "grad_norm": 0.8766434192657471,
      "learning_rate": 6.983791402396054e-05,
      "loss": 0.2939,
      "step": 430
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 1.3382691144943237,
      "learning_rate": 6.913319238900634e-05,
      "loss": 0.222,
      "step": 440
    },
    {
      "epoch": 0.9513742071881607,
      "grad_norm": 1.438628077507019,
      "learning_rate": 6.842847075405216e-05,
      "loss": 0.2687,
      "step": 450
    },
    {
      "epoch": 0.9725158562367865,
      "grad_norm": 0.7959738373756409,
      "learning_rate": 6.772374911909796e-05,
      "loss": 0.2557,
      "step": 460
    },
    {
      "epoch": 0.9936575052854123,
      "grad_norm": 1.8739782571792603,
      "learning_rate": 6.701902748414378e-05,
      "loss": 0.2779,
      "step": 470
    },
    {
      "epoch": 1.014799154334038,
      "grad_norm": 1.2330316305160522,
      "learning_rate": 6.631430584918958e-05,
      "loss": 0.2635,
      "step": 480
    },
    {
      "epoch": 1.0359408033826638,
      "grad_norm": 2.0109777450561523,
      "learning_rate": 6.560958421423538e-05,
      "loss": 0.2069,
      "step": 490
    },
    {
      "epoch": 1.0570824524312896,
      "grad_norm": 2.0927159786224365,
      "learning_rate": 6.490486257928118e-05,
      "loss": 0.2105,
      "step": 500
    },
    {
      "epoch": 1.0782241014799154,
      "grad_norm": 1.885388731956482,
      "learning_rate": 6.420014094432699e-05,
      "loss": 0.2696,
      "step": 510
    },
    {
      "epoch": 1.0993657505285412,
      "grad_norm": 0.7001839876174927,
      "learning_rate": 6.34954193093728e-05,
      "loss": 0.217,
      "step": 520
    },
    {
      "epoch": 1.120507399577167,
      "grad_norm": 0.8424420952796936,
      "learning_rate": 6.27906976744186e-05,
      "loss": 0.2135,
      "step": 530
    },
    {
      "epoch": 1.1416490486257929,
      "grad_norm": 1.6278246641159058,
      "learning_rate": 6.20859760394644e-05,
      "loss": 0.2155,
      "step": 540
    },
    {
      "epoch": 1.1627906976744187,
      "grad_norm": 1.3050992488861084,
      "learning_rate": 6.138125440451022e-05,
      "loss": 0.2124,
      "step": 550
    },
    {
      "epoch": 1.1839323467230445,
      "grad_norm": 1.8095475435256958,
      "learning_rate": 6.0676532769556024e-05,
      "loss": 0.2641,
      "step": 560
    },
    {
      "epoch": 1.20507399577167,
      "grad_norm": 1.178304672241211,
      "learning_rate": 5.997181113460183e-05,
      "loss": 0.2189,
      "step": 570
    },
    {
      "epoch": 1.226215644820296,
      "grad_norm": 2.0943214893341064,
      "learning_rate": 5.926708949964764e-05,
      "loss": 0.1863,
      "step": 580
    },
    {
      "epoch": 1.2473572938689217,
      "grad_norm": 2.0824389457702637,
      "learning_rate": 5.8562367864693445e-05,
      "loss": 0.2438,
      "step": 590
    },
    {
      "epoch": 1.2684989429175475,
      "grad_norm": 1.4540592432022095,
      "learning_rate": 5.785764622973926e-05,
      "loss": 0.2246,
      "step": 600
    },
    {
      "epoch": 1.2896405919661733,
      "grad_norm": 1.198023796081543,
      "learning_rate": 5.7152924594785064e-05,
      "loss": 0.2051,
      "step": 610
    },
    {
      "epoch": 1.3107822410147991,
      "grad_norm": 1.3449779748916626,
      "learning_rate": 5.6448202959830866e-05,
      "loss": 0.2704,
      "step": 620
    },
    {
      "epoch": 1.331923890063425,
      "grad_norm": 0.5767163634300232,
      "learning_rate": 5.5743481324876675e-05,
      "loss": 0.1886,
      "step": 630
    },
    {
      "epoch": 1.3530655391120507,
      "grad_norm": 0.6276868581771851,
      "learning_rate": 5.503875968992248e-05,
      "loss": 0.2336,
      "step": 640
    },
    {
      "epoch": 1.3742071881606766,
      "grad_norm": 1.1067684888839722,
      "learning_rate": 5.4334038054968294e-05,
      "loss": 0.2234,
      "step": 650
    },
    {
      "epoch": 1.3953488372093024,
      "grad_norm": 0.9234940409660339,
      "learning_rate": 5.3629316420014096e-05,
      "loss": 0.168,
      "step": 660
    },
    {
      "epoch": 1.4164904862579282,
      "grad_norm": 1.703173279762268,
      "learning_rate": 5.29245947850599e-05,
      "loss": 0.215,
      "step": 670
    },
    {
      "epoch": 1.437632135306554,
      "grad_norm": 1.877985954284668,
      "learning_rate": 5.2219873150105715e-05,
      "loss": 0.2283,
      "step": 680
    },
    {
      "epoch": 1.4587737843551798,
      "grad_norm": 3.4364442825317383,
      "learning_rate": 5.151515151515152e-05,
      "loss": 0.2084,
      "step": 690
    },
    {
      "epoch": 1.4799154334038054,
      "grad_norm": 1.1719492673873901,
      "learning_rate": 5.081042988019733e-05,
      "loss": 0.2179,
      "step": 700
    },
    {
      "epoch": 1.5010570824524314,
      "grad_norm": 1.2497189044952393,
      "learning_rate": 5.0105708245243135e-05,
      "loss": 0.2257,
      "step": 710
    },
    {
      "epoch": 1.522198731501057,
      "grad_norm": 1.3380656242370605,
      "learning_rate": 4.940098661028894e-05,
      "loss": 0.2082,
      "step": 720
    },
    {
      "epoch": 1.543340380549683,
      "grad_norm": 1.780739426612854,
      "learning_rate": 4.869626497533474e-05,
      "loss": 0.1996,
      "step": 730
    },
    {
      "epoch": 1.5644820295983086,
      "grad_norm": 2.6249661445617676,
      "learning_rate": 4.799154334038055e-05,
      "loss": 0.2822,
      "step": 740
    },
    {
      "epoch": 1.5856236786469344,
      "grad_norm": 1.5395492315292358,
      "learning_rate": 4.728682170542636e-05,
      "loss": 0.1702,
      "step": 750
    },
    {
      "epoch": 1.6067653276955602,
      "grad_norm": 2.9844987392425537,
      "learning_rate": 4.658210007047217e-05,
      "loss": 0.2232,
      "step": 760
    },
    {
      "epoch": 1.627906976744186,
      "grad_norm": 2.720681667327881,
      "learning_rate": 4.587737843551797e-05,
      "loss": 0.2026,
      "step": 770
    },
    {
      "epoch": 1.6490486257928119,
      "grad_norm": 1.0342341661453247,
      "learning_rate": 4.517265680056378e-05,
      "loss": 0.204,
      "step": 780
    },
    {
      "epoch": 1.6701902748414377,
      "grad_norm": 2.82182240486145,
      "learning_rate": 4.446793516560959e-05,
      "loss": 0.2254,
      "step": 790
    },
    {
      "epoch": 1.6913319238900635,
      "grad_norm": 1.5971125364303589,
      "learning_rate": 4.37632135306554e-05,
      "loss": 0.2579,
      "step": 800
    },
    {
      "epoch": 1.712473572938689,
      "grad_norm": 1.2186717987060547,
      "learning_rate": 4.30584918957012e-05,
      "loss": 0.2139,
      "step": 810
    },
    {
      "epoch": 1.733615221987315,
      "grad_norm": 1.4292373657226562,
      "learning_rate": 4.2353770260747e-05,
      "loss": 0.1892,
      "step": 820
    },
    {
      "epoch": 1.7547568710359407,
      "grad_norm": 1.2394386529922485,
      "learning_rate": 4.164904862579281e-05,
      "loss": 0.2245,
      "step": 830
    },
    {
      "epoch": 1.7758985200845667,
      "grad_norm": 1.4494390487670898,
      "learning_rate": 4.094432699083862e-05,
      "loss": 0.1746,
      "step": 840
    },
    {
      "epoch": 1.7970401691331923,
      "grad_norm": 1.75983726978302,
      "learning_rate": 4.023960535588443e-05,
      "loss": 0.2243,
      "step": 850
    },
    {
      "epoch": 1.8181818181818183,
      "grad_norm": 0.9670512080192566,
      "learning_rate": 3.953488372093023e-05,
      "loss": 0.2138,
      "step": 860
    },
    {
      "epoch": 1.839323467230444,
      "grad_norm": 4.969731330871582,
      "learning_rate": 3.883016208597604e-05,
      "loss": 0.1946,
      "step": 870
    },
    {
      "epoch": 1.8604651162790697,
      "grad_norm": 1.1889941692352295,
      "learning_rate": 3.812544045102185e-05,
      "loss": 0.1732,
      "step": 880
    },
    {
      "epoch": 1.8816067653276956,
      "grad_norm": 1.4506170749664307,
      "learning_rate": 3.7420718816067654e-05,
      "loss": 0.2205,
      "step": 890
    },
    {
      "epoch": 1.9027484143763214,
      "grad_norm": 2.6761703491210938,
      "learning_rate": 3.6715997181113456e-05,
      "loss": 0.2312,
      "step": 900
    },
    {
      "epoch": 1.9238900634249472,
      "grad_norm": 1.5670859813690186,
      "learning_rate": 3.6011275546159265e-05,
      "loss": 0.2127,
      "step": 910
    },
    {
      "epoch": 1.945031712473573,
      "grad_norm": 1.4168599843978882,
      "learning_rate": 3.5306553911205075e-05,
      "loss": 0.1976,
      "step": 920
    },
    {
      "epoch": 1.9661733615221988,
      "grad_norm": 1.7377710342407227,
      "learning_rate": 3.4601832276250884e-05,
      "loss": 0.1768,
      "step": 930
    },
    {
      "epoch": 1.9873150105708244,
      "grad_norm": 3.4468514919281006,
      "learning_rate": 3.389711064129669e-05,
      "loss": 0.1699,
      "step": 940
    },
    {
      "epoch": 2.0084566596194504,
      "grad_norm": 1.1995151042938232,
      "learning_rate": 3.3192389006342495e-05,
      "loss": 0.1514,
      "step": 950
    },
    {
      "epoch": 2.029598308668076,
      "grad_norm": 1.3688946962356567,
      "learning_rate": 3.2487667371388305e-05,
      "loss": 0.1821,
      "step": 960
    },
    {
      "epoch": 2.050739957716702,
      "grad_norm": 1.305660367012024,
      "learning_rate": 3.1782945736434114e-05,
      "loss": 0.149,
      "step": 970
    },
    {
      "epoch": 2.0718816067653276,
      "grad_norm": 1.2906973361968994,
      "learning_rate": 3.1078224101479916e-05,
      "loss": 0.1789,
      "step": 980
    },
    {
      "epoch": 2.0930232558139537,
      "grad_norm": 2.5298707485198975,
      "learning_rate": 3.0373502466525722e-05,
      "loss": 0.1571,
      "step": 990
    },
    {
      "epoch": 2.1141649048625792,
      "grad_norm": 0.8622164726257324,
      "learning_rate": 2.966878083157153e-05,
      "loss": 0.1895,
      "step": 1000
    },
    {
      "epoch": 2.1353065539112053,
      "grad_norm": 2.006359577178955,
      "learning_rate": 2.8964059196617337e-05,
      "loss": 0.1859,
      "step": 1010
    },
    {
      "epoch": 2.156448202959831,
      "grad_norm": 0.7105270624160767,
      "learning_rate": 2.8259337561663146e-05,
      "loss": 0.2163,
      "step": 1020
    },
    {
      "epoch": 2.177589852008457,
      "grad_norm": 1.7839833498001099,
      "learning_rate": 2.755461592670895e-05,
      "loss": 0.177,
      "step": 1030
    },
    {
      "epoch": 2.1987315010570825,
      "grad_norm": 1.82643461227417,
      "learning_rate": 2.6849894291754758e-05,
      "loss": 0.1385,
      "step": 1040
    },
    {
      "epoch": 2.219873150105708,
      "grad_norm": 1.8831154108047485,
      "learning_rate": 2.6145172656800564e-05,
      "loss": 0.1221,
      "step": 1050
    },
    {
      "epoch": 2.241014799154334,
      "grad_norm": 2.687443971633911,
      "learning_rate": 2.5440451021846373e-05,
      "loss": 0.1952,
      "step": 1060
    },
    {
      "epoch": 2.2621564482029597,
      "grad_norm": 1.4433428049087524,
      "learning_rate": 2.473572938689218e-05,
      "loss": 0.1622,
      "step": 1070
    },
    {
      "epoch": 2.2832980972515857,
      "grad_norm": 1.312044382095337,
      "learning_rate": 2.4031007751937988e-05,
      "loss": 0.1387,
      "step": 1080
    },
    {
      "epoch": 2.3044397463002113,
      "grad_norm": 1.6357488632202148,
      "learning_rate": 2.332628611698379e-05,
      "loss": 0.1579,
      "step": 1090
    },
    {
      "epoch": 2.3255813953488373,
      "grad_norm": 2.7747645378112793,
      "learning_rate": 2.26215644820296e-05,
      "loss": 0.1588,
      "step": 1100
    },
    {
      "epoch": 2.346723044397463,
      "grad_norm": 1.2531894445419312,
      "learning_rate": 2.1916842847075405e-05,
      "loss": 0.1703,
      "step": 1110
    },
    {
      "epoch": 2.367864693446089,
      "grad_norm": 2.3051016330718994,
      "learning_rate": 2.1212121212121215e-05,
      "loss": 0.1947,
      "step": 1120
    },
    {
      "epoch": 2.3890063424947146,
      "grad_norm": 2.1935160160064697,
      "learning_rate": 2.050739957716702e-05,
      "loss": 0.1916,
      "step": 1130
    },
    {
      "epoch": 2.41014799154334,
      "grad_norm": 1.5347408056259155,
      "learning_rate": 1.9802677942212826e-05,
      "loss": 0.1708,
      "step": 1140
    },
    {
      "epoch": 2.431289640591966,
      "grad_norm": 3.1375014781951904,
      "learning_rate": 1.9097956307258632e-05,
      "loss": 0.1633,
      "step": 1150
    },
    {
      "epoch": 2.452431289640592,
      "grad_norm": 3.5195486545562744,
      "learning_rate": 1.839323467230444e-05,
      "loss": 0.1632,
      "step": 1160
    },
    {
      "epoch": 2.473572938689218,
      "grad_norm": 2.4272994995117188,
      "learning_rate": 1.7688513037350247e-05,
      "loss": 0.1433,
      "step": 1170
    },
    {
      "epoch": 2.4947145877378434,
      "grad_norm": 4.194243431091309,
      "learning_rate": 1.6983791402396053e-05,
      "loss": 0.1868,
      "step": 1180
    },
    {
      "epoch": 2.5158562367864694,
      "grad_norm": 1.2591652870178223,
      "learning_rate": 1.6279069767441862e-05,
      "loss": 0.1572,
      "step": 1190
    },
    {
      "epoch": 2.536997885835095,
      "grad_norm": 3.1440231800079346,
      "learning_rate": 1.5574348132487668e-05,
      "loss": 0.1734,
      "step": 1200
    },
    {
      "epoch": 2.558139534883721,
      "grad_norm": 1.890101671218872,
      "learning_rate": 1.4869626497533476e-05,
      "loss": 0.1809,
      "step": 1210
    },
    {
      "epoch": 2.5792811839323466,
      "grad_norm": 1.8750766515731812,
      "learning_rate": 1.4164904862579281e-05,
      "loss": 0.1487,
      "step": 1220
    },
    {
      "epoch": 2.6004228329809727,
      "grad_norm": 2.097666025161743,
      "learning_rate": 1.3460183227625089e-05,
      "loss": 0.1745,
      "step": 1230
    },
    {
      "epoch": 2.6215644820295982,
      "grad_norm": 1.661858320236206,
      "learning_rate": 1.2755461592670895e-05,
      "loss": 0.1506,
      "step": 1240
    },
    {
      "epoch": 2.6427061310782243,
      "grad_norm": 1.9351832866668701,
      "learning_rate": 1.2050739957716702e-05,
      "loss": 0.2555,
      "step": 1250
    },
    {
      "epoch": 2.66384778012685,
      "grad_norm": 0.7988278865814209,
      "learning_rate": 1.134601832276251e-05,
      "loss": 0.2067,
      "step": 1260
    },
    {
      "epoch": 2.6849894291754755,
      "grad_norm": 1.3852460384368896,
      "learning_rate": 1.0641296687808317e-05,
      "loss": 0.1665,
      "step": 1270
    },
    {
      "epoch": 2.7061310782241015,
      "grad_norm": 2.4913196563720703,
      "learning_rate": 9.936575052854123e-06,
      "loss": 0.1308,
      "step": 1280
    },
    {
      "epoch": 2.7272727272727275,
      "grad_norm": 1.1723785400390625,
      "learning_rate": 9.23185341789993e-06,
      "loss": 0.1504,
      "step": 1290
    },
    {
      "epoch": 2.748414376321353,
      "grad_norm": 1.100695252418518,
      "learning_rate": 8.527131782945736e-06,
      "loss": 0.1408,
      "step": 1300
    },
    {
      "epoch": 2.7695560253699787,
      "grad_norm": 3.050225019454956,
      "learning_rate": 7.822410147991544e-06,
      "loss": 0.1503,
      "step": 1310
    },
    {
      "epoch": 2.7906976744186047,
      "grad_norm": 1.6665284633636475,
      "learning_rate": 7.1176885130373506e-06,
      "loss": 0.1458,
      "step": 1320
    },
    {
      "epoch": 2.8118393234672303,
      "grad_norm": 2.3004167079925537,
      "learning_rate": 6.412966878083157e-06,
      "loss": 0.1669,
      "step": 1330
    },
    {
      "epoch": 2.8329809725158563,
      "grad_norm": 0.6278007626533508,
      "learning_rate": 5.708245243128965e-06,
      "loss": 0.1508,
      "step": 1340
    },
    {
      "epoch": 2.854122621564482,
      "grad_norm": 2.0203938484191895,
      "learning_rate": 5.003523608174771e-06,
      "loss": 0.1525,
      "step": 1350
    },
    {
      "epoch": 2.875264270613108,
      "grad_norm": 0.7119584083557129,
      "learning_rate": 4.298801973220578e-06,
      "loss": 0.1344,
      "step": 1360
    },
    {
      "epoch": 2.8964059196617336,
      "grad_norm": 2.0269577503204346,
      "learning_rate": 3.5940803382663847e-06,
      "loss": 0.1538,
      "step": 1370
    },
    {
      "epoch": 2.9175475687103596,
      "grad_norm": 4.681911945343018,
      "learning_rate": 2.889358703312192e-06,
      "loss": 0.1726,
      "step": 1380
    },
    {
      "epoch": 2.938689217758985,
      "grad_norm": 1.6193246841430664,
      "learning_rate": 2.1846370683579985e-06,
      "loss": 0.1455,
      "step": 1390
    },
    {
      "epoch": 2.9598308668076108,
      "grad_norm": 4.514327526092529,
      "learning_rate": 1.4799154334038056e-06,
      "loss": 0.1763,
      "step": 1400
    }
  ],
  "logging_steps": 10,
  "max_steps": 1419,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 3,
  "save_steps": 200,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 1.1836099474839299e+18,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
